Tokenizer,Vocab Size,Num Hidden Layers,Hidden Size,Hidden Act,Hidden Dropout Prob,Intermediate Size,Num Attention Heads,Attention Probs Dropout Prob,Max Sequence Length,Position Embedding Type,Learning Rate,Batch Size,Size,Accuracy,FLOPS,Flips
3,7038,7,55,2,0.2,290,11,0.2,395,1,3,2,3.0018880000000001118,0.77675,2.63519115,245
1,28110,3,20,3,0.6,1269,5,0.6,354,3,3,2,3.045084000000000124,0.82025,1.260153624,79
3,13915,4,45,1,0.5,111,9,0.5,502,2,3,2,3.0005839999999999179,0.8325,2.595105064,149
1,2275,1,135,4,0.6,930,1,0.6,293,1,3,2,3.000892,0.85475,1.05148617,49
4,12365,4,22,3,0.3,2516,11,0.3,358,1,3,1,3.001288,0.87525,1.53062184,164
2,1490,1,180,2,0.6,424,9,0.6,365,1,3,1,3.000216,0.885,1.48379873,112
3,9053,2,36,2,0.3,2583,1,0.3,468,3,2,2,3.002336,0.94125,1.707031872,73
1,18091,2,30,3,0.3,1394,10,0.3,460,2,1,1,3.0006,0.947,1.76954824,63
3,14893,3,30,4,0.4,1461,10,0.4,380,1,2,1,3.0023,0.8715,1.54454952,215
3,1007,3,96,2,0.2,745,8,0.2,469,3,3,1,3.00146,0.9445,2.631804756,121
3,9170,4,30,3,0.2,1788,5,0.2,346,3,3,2,3.001504,0.89925,1.397015136,153
3,6130,1,60,2,0.3,2627,10,0.3,338,3,1,1,3.004844,0.94225,1.176029088,87
2,8455,4,40,1,0.3,1093,10,0.3,332,2,3,2,3.002344,0.897,1.472597952,127
3,8279,1,60,4,0.3,1462,6,0.3,447,1,3,1,3.000624,0.928,1.584170682,172
2,13968,1,36,4,0.4,2877,12,0.4,392,2,3,1,3.002212,0.9,1.351667744,132
1,32720,1,22,4,0.3,272,11,0.3,334,1,1,2,3.000136,0.92225,1.09128822,135
1,8448,3,36,4,0.6,1827,3,0.6,350,2,3,2,3.004756,0.85875,1.32972,63
1,1336,1,220,2,0.4,101,11,0.4,267,1,3,1,3.000548,0.9235,1.033959636,178
4,35493,2,16,1,0.3,2527,4,0.3,410,1,3,1,3.003008,0.82,1.39994992,127
1,10311,2,54,4,0.3,556,3,0.3,383,1,3,2,3.000488,0.894,1.439824156,139