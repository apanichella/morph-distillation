Tokenizer,Vocab Size,Num Hidden Layers,Hidden Size,Hidden Act,Hidden Dropout Prob,Intermediate Size,Num Attention Heads,Attention Probs Dropout Prob,Max Sequence Length,Position Embedding Type,Learning Rate,Batch Size,Size,Accuracy,FLOPS,Flips
1,18091,2,30,3,0.3,1394,10,0.3,460,2,1,1,3.0006,0.9295,1.76954824,96
3,1831,3,36,4,0.4,2941,4,0.4,280,2,1,2,3.0019,0.868,1.04615952,126
3,1831,3,36,4,0.4,2941,4,0.4,280,2,1,2,3.0019,0.893,1.04615952,100
4,5937,1,68,4,0.2,1968,2,0.2,347,3,3,2,3.002568,0.944,1.184739198,115
4,22745,3,18,1,0.2,2907,3,0.2,354,2,3,1,3.000076,0.8815,1.258410528,113
4,10453,4,24,2,0.6,2420,4,0.6,273,2,2,2,3.001208,0.865,1.01753652,73
2,2256,3,72,3,0.3,1084,8,0.3,285,3,3,1,3.000152,0.933,1.22170779,82
1,19179,7,24,2,0.2,738,12,0.2,367,2,3,2,3.000032,0.8865,1.94185939,204
2,8369,1,60,1,0.4,1509,3,0.4,353,3,3,1,3.001396,0.89625,1.196222396,74
2,16888,6,23,3,0.4,1183,1,0.4,282,2,2,1,3.000644,0.87875,1.068660432,139
1,7932,2,36,3,0.3,2934,12,0.3,301,1,3,1,3.0022,0.892,1.117291532,245
3,13584,7,20,1,0.3,1576,2,0.3,285,2,3,2,3.004824,0.88875,1.12497651,180
2,40827,3,16,2,0.3,851,8,0.3,267,2,2,1,3.00062,0.84075,0.93381648,300
1,34883,2,16,2,0.2,2671,8,0.2,372,1,2,1,3.00288,0.85375,1.30202976,244
3,14304,7,20,3,0.5,1517,1,0.5,366,1,1,2,3.001996,0.8035,1.489126632,224
3,12314,2,40,1,0.6,1340,4,0.6,297,3,3,2,3.001608,0.8665,1.04233338,92
2,1471,3,128,2,0.2,270,2,0.2,468,2,1,1,3.000016,0.849,2.779524072,120
1,2251,9,84,2,0.4,153,4,0.4,313,3,1,2,3.000388,0.919,2.264000364,130
4,32771,3,20,2,0.3,611,4,0.3,315,3,3,2,3.00218,0.83975,1.09506096,215